{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd8d713b-9207-49ed-a388-eb77bd8e3a64",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%pip install unstructured\n",
    "\n",
    "%pip install python-docx\n",
    "\n",
    "%pip install pypdfium2\n",
    "\n",
    "%pip install -qU langchain-text-splitters\n",
    "\n",
    "%pip install -U langgraph langsmith langchain_anthropic\n",
    "\n",
    "%pip install paramiko\n",
    "\n",
    "%pip install torch ChatTTS\n",
    "\n",
    "%pip install nvidia-riva-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad753cd8-f106-4b46-aa45-a4f825daf00f",
   "metadata": {},
   "source": [
    "%git clone https://github.com/nvidia-riva/python-clients.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e9b5bdcf-c491-4f2c-8204-2c262cea4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "NVIDIA_API_KEY = \"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\"\n",
    "os.environ[\"NVIDIA_API_KEY\"] = NVIDIA_API_KEY\n",
    "\n",
    "AUTODL_HOST=\"connect.seetacloud.com\"\n",
    "AUTODL_PORT=0000\n",
    "AUTODL_USER=\"\"\n",
    "AUTODL_PASSWORD=\"\"\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"lsv21bc7ffc\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"beauty_assistant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f384a07c-c76c-472b-ace7-335702afa7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "embedder = NVIDIAEmbeddings(model=\"NV-Embed-QA\")#ai-embed-qa-4\n",
    "llm_deepseek_r1 = ChatNVIDIA(\n",
    "      model=\"deepseek-ai/deepseek-r1\",\n",
    "      temperature=0.6,\n",
    "      top_p=0.7,\n",
    "      max_tokens=4096,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bd4ce13b-77c2-41bc-856f-468ed9a495bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import print_with_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0341e39a-4148-4a01-9d29-8e6d48b1d503",
   "metadata": {},
   "source": [
    "初始向量数据库，只需执行一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "199c707f-0618-45eb-b04d-af12f66c474b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from utility import LoadPDF\n",
    "\n",
    "def init_vector_store():\n",
    "    have_store=False\n",
    "    docs=LoadPDF(\"./kdoc\")\n",
    "    for doc in docs:\n",
    "        #print_with_time(doc)\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            # Set a really small chunk size, just to show.\n",
    "            chunk_size=100,\n",
    "            chunk_overlap=20,\n",
    "            length_function=len,\n",
    "            is_separator_regex=False,\n",
    "        )\n",
    "        texts = text_splitter.split_documents(doc)\n",
    "        print_with_time(texts[0])\n",
    "        if not have_store:\n",
    "            store = FAISS.from_documents(texts, embedder)\n",
    "            have_store=True\n",
    "        else:\n",
    "            tmp_store=FAISS.from_documents(texts, embedder)\n",
    "            store.merge_from(tmp_store)\n",
    "    store.save_local('./embedding')\n",
    "    \n",
    "# 初始向量数据库，只需执行一次\n",
    "# init_vector_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0cbede3d-137b-4248-8efe-677e0526fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from entity import State\n",
    "\n",
    "def asr(state:State):\n",
    "    audio_file=state[\"question_audio\"]\n",
    "    cmd=f\"\"\"python python-clients/scripts/asr/transcribe_file_offline.py --server grpc.nvcf.nvidia.com:443 --use-ssl  --metadata function-id \"b702f636-f60c-4a3d-a6f4-f3568c13bd7d\" --metadata \"authorization\" \"Bearer {NVIDIA_API_KEY}\"  --language-code en --input-file {audio_file}\"\"\"\n",
    "    print_with_time(cmd)\n",
    "    process  = subprocess.Popen(cmd, stdout=subprocess.PIPE, text=True)\n",
    "    output, errors = process.communicate()\n",
    "    # print( output, errors )\n",
    "    arr=output.split(\"Final transcript: \")\n",
    "    if(len(arr)>=2):\n",
    "        return {\"question\":arr[1],\"messages\": [{\"role\": \"user\", \"content\": arr[1]}]}\n",
    "    else:\n",
    "        print_with_time( output )\n",
    "        raise ValueError(\"asr出现错误\")\n",
    "    \n",
    "# s=State(question_audio=\"./asr_example_zh.wav\")\n",
    "# r=asr(s)\n",
    "# print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0733bbdf-c0e7-4a4d-a5be-f2c8b485b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import re\n",
    "import torch\n",
    "import torchaudio\n",
    "import ChatTTS\n",
    "from IPython.display import Audio\n",
    "from utility import is_file_empty\n",
    "\n",
    " \n",
    "def is_chinese(s):\n",
    "    pattern = re.compile(r'[\\u4e00-\\u9fff\\u3400-\\u4DBF\\u20000-\\u2A6DF]+')\n",
    "    return bool(pattern.match(s))\n",
    "\n",
    "def translate(str):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"你是一个中英文翻译专家，将用户输入的中文翻译成英文。直接翻译，不要解析内容。请简洁回答，不重复用户问题，并控制在100字以内。\n",
    "                \"\"\",\n",
    "            ),\n",
    "            (\"user\", f\"{str}\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    chain = (\n",
    "        prompt\n",
    "        | llm_deepseek_r1\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    result=chain.invoke({})\n",
    "    # print_with_time(result)\n",
    "    arr=result.split(\"</think>\")\n",
    "    # print_with_time(arr[-1])\n",
    "    if len(arr[-1])<=0:\n",
    "        print_with_time(result)\n",
    "        raise ValueError(\"中文翻译英文出现错误\")\n",
    "    return arr[-1]\n",
    "    \n",
    "# print(translate(\"春景短詩，捕捉梅香鳥驚、風過花落的瞬間，末句化用「花開花落知多少」感時傷逝，意象靈動，餘韻悠長。\"))\n",
    "\n",
    "def tts(state:State):\n",
    "    answer=state[\"answer\"].replace(\"'\",\"\").replace('\"','')\n",
    "    if is_chinese(answer):\n",
    "        answer=translate(answer) #接口不支持中文j\n",
    "    audio_path=\"./audio\"\n",
    "    if not os.path.exists(audio_path):\n",
    "        os.makedirs(audio_path)\n",
    "    output_audio=f\"{audio_path}/{uuid.uuid4()}.wav\"\n",
    "    cmd=f\"\"\"python python-clients/scripts/tts/talk.py  --server grpc.nvcf.nvidia.com:443 --use-ssl --metadata function-id \"5e607c81-7aa6-44ce-a11d-9e08f0a3fe49\"  --metadata authorization \"Bearer {NVIDIA_API_KEY}\" --text \"{answer}\" --voice \"English-US-RadTTS.Female-1\" --output {output_audio}\"\"\"\n",
    "    print_with_time(cmd)\n",
    "    process  = subprocess.Popen(cmd, stdout=subprocess.PIPE, text=True)\n",
    "    output, errors = process.communicate()\n",
    "    if is_file_empty(output_audio):\n",
    "        print_with_time( output, errors )\n",
    "        raise ValueError(\"tts出现错误\")\n",
    "    return  {\"answer_audio\":output_audio}\n",
    "\n",
    "# s=State(answer=\"春景短詩，捕捉梅香鳥驚、風過花落的瞬間，末句化用「花開花落知多少」感時傷逝，意象靈動，餘韻悠長。\")\n",
    "# r=tts(s)\n",
    "# print(r)\n",
    "\n",
    "def chattts(state:State):\n",
    "    answer=state[\"answer\"]\n",
    "\n",
    "    audio_path=\"./audio\"\n",
    "    if not os.path.exists(audio_path):\n",
    "        os.makedirs(audio_path)\n",
    "    output_audio=f\"{audio_path}/{uuid.uuid4()}.wav\"\n",
    "\n",
    "    # 初始化ChatTTS\n",
    "    chat = ChatTTS.Chat()\n",
    "    chat.load()\n",
    "    # 定义要转换为语音的文本\n",
    "    texts = [answer]\n",
    "    # 生成语音\n",
    "    wavs = chat.infer(texts, use_decoder=True)\n",
    "    torchaudio.save(output_audio, torch.from_numpy(wavs[0]), 24000)\n",
    "    # 播放生成的音频\n",
    "    Audio(wavs[0], rate=24_000, autoplay=True)\n",
    "    if is_file_empty(output_audio):\n",
    "        print_with_time( output, errors )\n",
    "        raise ValueError(\"tts出现错误\")\n",
    "    return  {\"answer_audio\":output_audio}\n",
    "\n",
    "# s=State(answer=\"春景短詩，捕捉梅香鳥驚、風過花落的瞬間，末句化用「花開花落知多少」感時傷逝，意象靈動，餘韻悠長。\")\n",
    "# r=chattts(s)\n",
    "# print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dc3385c5-8141-491a-ad9c-ba6c929070ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paramiko\n",
    "import traceback\n",
    "from entity import State\n",
    "\n",
    "def audio2face(state:State):\n",
    "    try:\n",
    "        answer_audio=state[\"answer_audio\"]\n",
    "        ssh = paramiko.SSHClient()\n",
    "        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "        ssh.connect(hostname=AUTODL_HOST, port=AUTODL_PORT, username=AUTODL_USER, password=AUTODL_PASSWORD)\n",
    "    \n",
    "        file_name = os.path.basename(answer_audio)\n",
    "        remote_audio_file=f\"/root/Sonic/examples/wav/{file_name}\"\n",
    "        # 创建SFTP客户端\n",
    "        sftp = paramiko.SFTPClient.from_transport(ssh.get_transport())\n",
    "        # 上传文件 /root/autodl-tmp/\n",
    "        sftp.put(answer_audio, remote_audio_file)\n",
    "        # 关闭SFTP客户端\n",
    "        sftp.close()\n",
    "\n",
    "        file_name=f\"{uuid.uuid4()}.mp4\"\n",
    "        remote_video_file=f\"/root/Sonic/examples/wav/{file_name}\"\n",
    "        cmd=f\"/root/miniconda3/bin/python /root/Sonic/demo.py '/root/Sonic/examples/image/hair.png' '{remote_audio_file}' '{remote_video_file}'\"\n",
    "        print_with_time(cmd)\n",
    "        # 执行远程命令\n",
    "        # stdin, stdout, stderr = ssh.exec_command(\"sudo su\")\n",
    "        # stdin.write(f\"{AUTODL_PASSWORD}\\n\")\n",
    "        # stdin.flush()\n",
    "        stdin, stdout, stderr = ssh.exec_command(cmd)\n",
    "        # 打印命令输出\n",
    "        print(\"stdout\",stdout.read().decode())\n",
    "        print(\"stderr\",stderr.read().decode())\n",
    "        \n",
    "        video_path=\"./video\"\n",
    "        if not os.path.exists(video_path):\n",
    "            os.makedirs(video_path)\n",
    "        local_video_file=f\"{video_path}/{file_name}\"\n",
    "         # 创建SFTP客户端\n",
    "        sftp = paramiko.SFTPClient.from_transport(ssh.get_transport())\n",
    "        # 下载文件 /root/autodl-tmp/\n",
    "        sftp.get(remote_video_file, local_video_file)\n",
    "        # 关闭SFTP客户端\n",
    "        sftp.close()\n",
    "        \n",
    "        ssh.close()\n",
    "\n",
    "        if is_file_empty(local_video_file):\n",
    "            print(\"stdout\",stdout.read().decode())\n",
    "            print(\"stderr\",stderr.read().decode())\n",
    "            raise ValueError(\"audio2face出现错误\")\n",
    "        return  {\"answer_video\":local_video_file}\n",
    "    except Exception as e:\n",
    "        error_msg = traceback.format_exc()\n",
    "        print_with_time(error_msg)\n",
    "        raise ValueError(\"audio2face出现错误\")\n",
    "        \n",
    "    return  {\"answer_video\":\"\"}\n",
    "    \n",
    "\n",
    "# s=State(answer_audio=\"./audio/c07eaa93-66ae-41df-8c82-64a6dd6be988.wav\")\n",
    "# r=audio2face(s)\n",
    "# print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "822a4fe3-316d-49cb-808d-1a2ccf7f4941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Router\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from utility import PPrint\n",
    "from entity import RouteQuery,State\n",
    "\n",
    "def route_question(state:State):\n",
    "    \"\"\"\n",
    "    Route question to direct answer or RAG.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    print_with_time(\"route_question\")\n",
    "    \n",
    "    system = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "    The vectorstore contains documents related to internal company information, IT technical knowledge, and adversarial attacks.\n",
    "    Use the vectorstore for questions on these topics. Otherwise, use direct_answer.\n",
    "    以 JSON 的形式输出，输出的 JSON 需遵守以下的格式：\n",
    "\n",
    "    {{\n",
    "      \"datasource\": <数据来源，值为 vectorstore 或者 direct_answer>\n",
    "    }}\"\"\"\n",
    "    route_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "    # print(route_prompt)\n",
    "    \n",
    "    structure_parser = PydanticOutputParser(pydantic_object=RouteQuery)\n",
    "    # print(structure_parser.get_format_instructions())\n",
    "\n",
    "    chain = (\n",
    "        route_prompt\n",
    "        | llm_deepseek_r1 \n",
    "        # | PPrint()\n",
    "        | structure_parser\n",
    "        # | StrOutputParser()\n",
    "    )\n",
    "    question = state[\"question\"]\n",
    "    source =chain.invoke({\"question\": question})\n",
    "    if source.datasource == \"vectorstore\":\n",
    "        return \"vectorstore\"\n",
    "    else:\n",
    "        return \"direct_answer\"\n",
    "\n",
    "# s=State(question=\"手语识别(SLR)技术是什么\")\n",
    "# print(route_question(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fa268639-7745-4dfa-acd1-8bd763283bcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "def retrieve(state):\n",
    "    print_with_time(\"retrieve\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "\n",
    "    store = FAISS.load_local(\"./embedding\", embedder,allow_dangerous_deserialization=True)\n",
    "    retriever = store.as_retriever(search_kwargs={\"k\": 3})\n",
    "    documents  = retriever.invoke(question)\n",
    "    return {\"documents\": documents }\n",
    "\n",
    "# s=State(question=\" 不a见\")\n",
    "# print(retrieve(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "da137f13-1afb-4ce8-92bc-7227e59159e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval Grader\n",
    "from entity import GradeDocuments\n",
    "from entity import State\n",
    "\n",
    "def grade_documents(state):\n",
    "    print_with_time(\"grade_documents\")\n",
    "    \n",
    "    question=state[\"question\"]\n",
    "    documents=state[\"documents\"]\n",
    "    \n",
    "    # Prompt\n",
    "    system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
    "        以 JSON 的形式输出，输出的 JSON 需遵守以下的格式：\n",
    "\n",
    "        {{\n",
    "          \"binary_score\": <相关度，值为 yes 或者 no>\n",
    "        }}\"\"\"\n",
    "    grade_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    structure_parser = PydanticOutputParser(pydantic_object=GradeDocuments)\n",
    "    # print(structure_parser.get_format_instructions())\n",
    "\n",
    "    chain = (\n",
    "        grade_prompt\n",
    "        | llm_deepseek_r1 \n",
    "        # | PPrint()\n",
    "        | structure_parser\n",
    "        # | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    filtered_docs=[]\n",
    "    for d in documents:\n",
    "        score=chain.invoke({\"question\": question, \"document\": d.page_content})\n",
    "        # print(d,score)\n",
    "        grade=score.binary_score\n",
    "        if grade==\"yes\":\n",
    "            filtered_docs.append(d)\n",
    "            \n",
    "        # break\n",
    "            \n",
    "    return {\"documents\": filtered_docs }\n",
    "\n",
    "# s=State(question=\"手语识别(SLR)技术是什么\")\n",
    "# docs=retrieve(s)\n",
    "# s=State(question=\"手语识别(SLR)技术是什么\",documents= docs[\"documents\"])\n",
    "# print(grade_documents(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cda7c7e1-5d2e-450d-8bf8-6a5ea0abdaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    print_with_time(\"decide_to_generate\")\n",
    "    \n",
    "    documents=state[\"documents\"]\n",
    "    if(len(documents)>0):\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        return \"direct_answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cc0189c5-eccd-45ea-9c9f-9fa5712351b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate\n",
    "def generate(state):\n",
    "    print_with_time(\"generate\")\n",
    "    \n",
    "    question=state[\"question\"]\n",
    "    documents=state[\"documents\"]\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"Please provide a concise answer without repeating the user's question, keeping it under 100 characters. answer solely based on the following context:\\n<Documents>\\n{context}\\n</Documents>.\n",
    "                \"\"\",\n",
    "            ),\n",
    "            (\"user\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    chain = (\n",
    "        prompt\n",
    "        | llm_deepseek_r1\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    result=chain.invoke({\"context\": documents, \"question\": question})\n",
    "    arr=result.split()\n",
    "    if len(arr[-1])<=0:\n",
    "        print_with_time(result)\n",
    "        raise ValueError(\"generate出现错误\")\n",
    "    return {\"answer\": arr[-1] ,\"messages\": [{\"role\": \"assistant\", \"content\": arr[-1]}]}\n",
    "    \n",
    "# s=State(question=\"手语识别(SLR)技术是什么\")\n",
    "# docs=retrieve(s)\n",
    "# s=State(question=\"手语识别(SLR)技术是什么\",documents= docs[\"documents\"])\n",
    "# print(generate(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4151a08a-8c63-49c3-9bac-9a9296504516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_answer(state):\n",
    "    print_with_time(\"direct_answer\")\n",
    "    \n",
    "    question=state[\"question\"]\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"Please provide a concise answer without repeating the user's question, keeping it under 100 characters. \n",
    "                \"\"\",\n",
    "            ),\n",
    "            (\"user\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    chain = (\n",
    "        prompt\n",
    "        | llm_deepseek_r1\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    result=chain.invoke({\"question\": question})\n",
    "    arr=result.split()\n",
    "    if len(arr[-1])<=0:\n",
    "        print_with_time(result)\n",
    "        raise ValueError(\"direct_answer出现错误\")\n",
    "    return {\"answer\": arr[-1] ,\"messages\": [{\"role\": \"assistant\", \"content\": arr[-1]}]}\n",
    "\n",
    "# s=State(question=\"手语识别(SLR)技术是什么\")\n",
    "# print(direct_answer(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "29abaefc-ae61-4b3f-ac5a-219ea7b061fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod\n",
    "from entity import State\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"asr\", asr)\n",
    "graph_builder.add_node(\"tts\", tts)\n",
    "graph_builder.add_node(\"audio2face\", audio2face)\n",
    "graph_builder.add_node(\"retrieve\", retrieve)\n",
    "graph_builder.add_node(\"grade_documents\", grade_documents)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "graph_builder.add_node(\"direct_answer\", direct_answer)\n",
    "\n",
    "graph_builder.add_edge(START, \"asr\")\n",
    "graph_builder.add_conditional_edges(\"asr\",\n",
    "                                    route_question,\n",
    "                                    {\"vectorstore\": \"retrieve\", \"direct_answer\": \"direct_answer\"}\n",
    "                                   )\n",
    "graph_builder.add_edge(\"retrieve\", \"grade_documents\")\n",
    "graph_builder.add_conditional_edges(\"grade_documents\", \n",
    "                       decide_to_generate,\n",
    "                       {\"generate\": \"generate\", \"direct_answer\": \"direct_answer\"}\n",
    "                      )\n",
    "graph_builder.add_edge(\"generate\", \"tts\")\n",
    "graph_builder.add_edge(\"direct_answer\", \"tts\")\n",
    "graph_builder.add_edge(\"tts\", \"audio2face\")\n",
    "graph_builder.add_edge(\"audio2face\", END)\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "    graph.get_graph().draw_mermaid_png(output_file_path=\"beauty_assistant.png\")\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c76ab60d-3041-4059-84d6-04ff05b95815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle(audio):\n",
    "    print_with_time(\"开始处理\")\n",
    "\n",
    "    yield \"./video/prologue.mp4\",\"等待响应\"\n",
    "    try:\n",
    "        \n",
    "        video=\"\"\n",
    "        answer=\"\"\n",
    "        for event in graph.stream({\"question_audio\":audio}):\n",
    "            for value in event.values():\n",
    "                print_with_time(\"=\"*100)\n",
    "                print_with_time(value)\n",
    "                if value.get(\"answer_video\"):\n",
    "                    video=value[\"answer_video\"]\n",
    "                if value.get(\"answer\"):\n",
    "                    answer=value[\"answer\"]\n",
    "        if video==\"\":\n",
    "            video=\"./video/prologue.mp4\"\n",
    "        yield video,answer\n",
    "    except Exception as e:\n",
    "        error_msg = traceback.format_exc()\n",
    "        print_with_time(error_msg)\n",
    "        yield \"./video/prologue.mp4\",e.args\n",
    "\n",
    "    print_with_time(\"处理结束\")\n",
    "# handle(\"./test.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941560b-73bf-484c-88ef-5e1a7d42ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:5000\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:5000/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "with gr.Blocks(title=\"Bolt美女助理\") as block:\n",
    "    gr.HTML(\n",
    "        f\"\"\"\n",
    "        <h1 style='text-align: center;'>美女助理 </h1>\n",
    "        <h3 style='text-align: center;'> 让上班的牛马也可以享受美女的服务 </h3>\n",
    "        <p style='text-align: center;'> Powered by <a href=\"https://github.com/huggingface/parler-tts\"> Bolt</a>\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # with gr.Row():\n",
    "    #     with gr.Column(scale=1):\n",
    "    #         audio_in = gr.Audio(label=\"我\", sources=\"microphone\",type=\"filepath\")\n",
    "    #     with gr.Column(scale=4):\n",
    "    #         with gr.Group():\n",
    "    #             audio_out = gr.Video(label=\"美女\",autoplay=True,value=\"./video/prologue.mp4\",height=500)\n",
    "    #             answer = gr.Textbox(show_label=False)\n",
    "    audio_out = gr.Video(label=\"美女\",autoplay=True,value=\"./video/prologue.mp4\",height=500)\n",
    "    answer = gr.Textbox(show_label=False)\n",
    "    audio_in = gr.Audio(label=\"我\", sources=\"microphone\",type=\"filepath\")\n",
    "    \n",
    "        \n",
    "    audio_in.stop_recording(handle, audio_in, [audio_out,answer ])\n",
    "\n",
    "block.launch(debug=True, share=False, show_api=False, server_port=5000, server_name=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ed999-15e1-4eec-b019-656c49a58ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
